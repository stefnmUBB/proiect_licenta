\par Text extraction from images raises new challenges as opposed to analyzing the geometry data built up while the user writes on a pen-to-screen system in real time, also known as online recognition. A picture of a handwritten text misses the privilege of a compact and meaningful representation of the curves that make up the text. One would approach this inconvenient by trying to extract useful features \cite{featext} from a given image beforehand in order to improve the accuracy of the prediction. The difficulty of this task heavily depends on the quality of the input. Weak methods are prone to disturbances by factors like a change in brightness, noise, orientation, unforeseen objects near text \cite{Juan}. 

This chapters focuses on briefly describing different ways to HTR found in literature with emphasis on deep learning solutions, followed by the author's own perspective over the problem and experiments.